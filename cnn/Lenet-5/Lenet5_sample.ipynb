{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lenet5_sample.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOfnyNYSsJiHbJu0fY/DEmI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"KBlnyBeVHgiJ"},"source":["# coding: utf-8\n","\n","# ### Implementing LeNet-5 Architecture On MNIST Dataset (GPU Implementation)\n","\n","# In[1]:\n","\n","import torch\n","torch.multiprocessing.set_start_method(\"spawn\")        # https://github.com/pytorch/pytorch/issues/3491#event-1326332533\n","import torch.nn   \n","import torch.optim \n","import torch.nn.functional \n","import torchvision.datasets   \n","import torchvision.transforms     \n","\n","from torch import np   # this is torch's wrapper for numpy \n","import matplotlib\n","matplotlib.use('Agg')       \n","get_ipython().magic('matplotlib inline')\n","from matplotlib import pyplot    \n","from matplotlib.pyplot import subplot     \n","from sklearn.metrics import accuracy_score\n","\n","\n","# In[2]:\n","\n","# ---------- MNIST data from torch ----------     \n","# First download the dataset and set aside training and test data. Then perform transformation.  \n","# 'torchvision.transforms.compose()' creates a series of transformations to be applied on dataset. \n","# 'torchvision' reads datasets into PILImage (Python imaging format) which are in [0, 255] range. \n","# 'torchvision.transforms.ToTensor()' converts the PIL Image from range [0, 255] to a FloatTensor of \n","# shape (C x H x W) with range [0.0, 1.0]\n","# We then renormalize the input of range [0, 1] to range [-1, 1] using Î¼ = 0.5 and standard deviation = 0.5\n","\n","# [Refer line 73] http://pytorch.org/docs/0.2.0/_modules/torchvision/datasets/mnist.html\n","# [Refer 'ToTensor' class] http://pytorch.org/docs/0.2.0/_modules/torchvision/transforms.html\n","\n","transformImg = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n","                                               torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","train = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transformImg)\n","valid = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transformImg)\n","test = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transformImg)  \n","\n","# create training and validation set indexes (80-20 split)\n","idx = list(range(len(train)))\n","np.random.seed(1009)\n","np.random.shuffle(idx)          \n","train_idx = idx[ : int(0.8 * len(idx))]       \n","valid_idx = idx[int(0.8 * len(idx)) : ]\n","\n","\n","# In[3]:\n","\n","# sample images\n","fig1 = train.train_data[0].numpy()  \n","fig2 = train.train_data[2500].numpy()\n","fig3 = train.train_data[25000].numpy()  \n","fig4 = train.train_data[59999].numpy()\n","subplot(2,2,1), pyplot.imshow(fig1)  \n","subplot(2,2,2), pyplot.imshow(fig2) \n","subplot(2,2,3), pyplot.imshow(fig3)\n","subplot(2,2,4), pyplot.imshow(fig4)\n","\n","\n","# In[4]:\n","\n","# generate training and validation set samples\n","train_set = torch.utils.data.sampler.SubsetRandomSampler(train_idx)    \n","valid_set = torch.utils.data.sampler.SubsetRandomSampler(valid_idx)  \n","\n","# Load training and validation data based on above samples\n","# Size of an individual batch during training and validation is 30\n","# Both training and validation datasets are shuffled at every epoch by 'SubsetRandomSampler()'. Test set is not shuffled.\n","train_loader = torch.utils.data.DataLoader(train, batch_size=30, sampler=train_set, num_workers=4)  \n","valid_loader = torch.utils.data.DataLoader(train, batch_size=30, sampler=valid_set, num_workers=4)    \n","test_loader = torch.utils.data.DataLoader(test, num_workers=4)       \n","\n","\n","# In[5]:\n","\n","# Defining the network (LeNet-5)  \n","class LeNet5(torch.nn.Module):          \n","     \n","    def __init__(self):     \n","        super(LeNet5, self).__init__()\n","        # Convolution (In LeNet-5, 32x32 images are given as input. Hence padding of 2 is done below)\n","        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2, bias=True)\n","        # Max-pooling\n","        self.max_pool_1 = torch.nn.MaxPool2d(kernel_size=2)\n","        # Convolution\n","        self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True)\n","        # Max-pooling\n","        self.max_pool_2 = torch.nn.MaxPool2d(kernel_size=2) \n","        # Fully connected layer\n","        self.fc1 = torch.nn.Linear(16*5*5, 120)   # convert matrix with 16*5*5 (= 400) features to a matrix of 120 features (columns)\n","        self.fc2 = torch.nn.Linear(120, 84)       # convert matrix with 120 features to a matrix of 84 features (columns)\n","        self.fc3 = torch.nn.Linear(84, 10)        # convert matrix with 84 features to a matrix of 10 features (columns)\n","        \n","    def forward(self, x):\n","        # convolve, then perform ReLU non-linearity\n","        x = torch.nn.functional.relu(self.conv1(x))  \n","        # max-pooling with 2x2 grid \n","        x = self.max_pool_1(x) \n","        # convolve, then perform ReLU non-linearity\n","        x = torch.nn.functional.relu(self.conv2(x))\n","        # max-pooling with 2x2 grid\n","        x = self.max_pool_2(x)\n","        # first flatten 'max_pool_2_out' to contain 16*5*5 columns\n","        # read through https://stackoverflow.com/a/42482819/7551231\n","        x = x.view(-1, 16*5*5)\n","        # FC-1, then perform ReLU non-linearity\n","        x = torch.nn.functional.relu(self.fc1(x))\n","        # FC-2, then perform ReLU non-linearity\n","        x = torch.nn.functional.relu(self.fc2(x))\n","        # FC-3\n","        x = self.fc3(x)\n","        \n","        return x\n","     \n","net = LeNet5()     \n","net.cuda()\n","\n","\n","# In[6]:\n","\n","# set up loss function -- 'SVM Loss' a.k.a 'Cross-Entropy Loss'\n","loss_func = torch.nn.CrossEntropyLoss()\n","       \n","# SGD used for optimization, momentum update used as parameter update  \n","optimization = torch.optim.SGD(net.parameters(), lr = 0.001, momentum=0.9)\n","\n","\n","# In[7]:\n","\n","# Let training begin!\n","numEpochs = 20    \n","training_accuracy = []     \n","validation_accuracy = []\n","\n","for epoch in range(numEpochs):\n","    \n","    # training set -- perform model training\n","    epoch_training_loss = 0.0\n","    num_batches = 0\n","    for batch_num, training_batch in enumerate(train_loader):        # 'enumerate' is a super helpful function        \n","        # split training data into inputs and labels\n","        inputs, labels = training_batch                              # 'training_batch' is a list               \n","        # wrap data in 'Variable'\n","        inputs, labels = torch.autograd.Variable(inputs.cuda()), torch.autograd.Variable(labels.cuda())        \n","        # Make gradients zero for parameters 'W', 'b'\n","        optimization.zero_grad()         \n","        # forward, backward pass with parameter update\n","        forward_output = net(inputs)\n","        loss = loss_func(forward_output, labels)\n","        loss.backward()   \n","        optimization.step()     \n","        # calculating loss \n","        epoch_training_loss += loss.data[0]\n","        num_batches += 1\n","        \n","    print(\"epoch: \", epoch, \", loss: \", epoch_training_loss/num_batches)            \n","     \n","    # calculate training set accuracy\n","    accuracy = 0.0 \n","    num_batches = 0\n","    for batch_num, training_batch in enumerate(train_loader):        # 'enumerate' is a super helpful function        \n","        num_batches += 1\n","        inputs, actual_val = training_batch\n","        # perform classification\n","        predicted_val = net(torch.autograd.Variable(inputs.cuda()))\n","        # convert 'predicted_val' tensor to numpy array and use 'numpy.argmax()' function    \n","        predicted_val = predicted_val.cpu().data.numpy()    # convert cuda() type to cpu(), then convert it to numpy\n","        predicted_val = np.argmax(predicted_val, axis = 1)  # retrieved max_values along every row    \n","        # accuracy   \n","        accuracy += accuracy_score(actual_val.numpy(), predicted_val)\n","    training_accuracy.append(accuracy/num_batches)   \n","\n","    # calculate validation set accuracy \n","    accuracy = 0.0 \n","    num_batches = 0\n","    for batch_num, validation_batch in enumerate(valid_loader):        # 'enumerate' is a super helpful function        \n","        num_batches += 1\n","        inputs, actual_val = validation_batch\n","        # perform classification\n","        predicted_val = net(torch.autograd.Variable(inputs.cuda()))    \n","        # convert 'predicted_val' tensor to numpy array and use 'numpy.argmax()' function    \n","        predicted_val = predicted_val.cpu().data.numpy()    # convert cuda() type to cpu(), then convert it to numpy\n","        predicted_val = np.argmax(predicted_val, axis = 1)  # retrieved max_values along every row    \n","        # accuracy        \n","        accuracy += accuracy_score(actual_val.numpy(), predicted_val)\n","    validation_accuracy.append(accuracy/num_batches)\n","\n","\n","# In[8]:\n","\n","epochs = list(range(numEpochs))\n","\n","# plotting training and validation accuracies\n","fig1 = pyplot.figure()\n","pyplot.plot(epochs, training_accuracy, 'r')\n","pyplot.plot(epochs, validation_accuracy, 'g')\n","pyplot.xlabel(\"Epochs\")\n","pyplot.ylabel(\"Accuracy\") \n","pyplot.show(fig1)\n","\n","\n","# In[9]:\n","\n","# test the model on test dataset\n","correct = 0\n","total = 0\n","for test_data in test_loader:\n","    total += 1\n","    inputs, actual_val = test_data \n","    # perform classification\n","    predicted_val = net(torch.autograd.Variable(inputs.cuda()))   \n","    # convert 'predicted_val' GPU tensor to CPU tensor and extract the column with max_score\n","    predicted_val = predicted_val.cpu().data\n","    max_score, idx = torch.max(predicted_val, 1)\n","    # compare it with actual value and estimate accuracy\n","    correct += (idx == actual_val).sum()\n","       \n","print(\"Classifier Accuracy: \", correct/total * 100)"],"execution_count":null,"outputs":[]}]}