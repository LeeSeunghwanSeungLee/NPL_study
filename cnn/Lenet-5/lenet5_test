{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lenet_001.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNWGWJ5iwn/pHk5u+toZaIs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"zOkug0yf5G42"},"source":["# 새 섹션"]},{"cell_type":"code","metadata":{"id":"P4ONTv3PQXmr"},"source":["import torch\n","import torchvision"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"594c0pDbQacQ"},"source":["# prepare dataset\n","\n","n_epochs = 3\n","batch_size_train = 64\n","batch_size_test = 1000\n","learning_rate = 0.01\n","momentum = 0.5\n","log_interval = 10\n","\n","random_seed = 1\n","torch.backends.cudnn.enabled = False\n","torch.manual_seed(random_seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ds_5a3A6Qxgh"},"source":["# TorchVision offers a lot of handy tranformation,\n","\n","train_loader = torch.utils.data.DataLoader(\n","  torchvision.datasets.MNIST('/files/', train=True, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize(\n","                                 (0.1307,), (0.3081,))\n","                             ])),\n","  batch_size=batch_size_train, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(\n","  torchvision.datasets.MNIST('/files/', train=False, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize(\n","                                 (0.1307,), (0.3081,))\n","                             ])),\n","  batch_size=batch_size_test, shuffle=True)\n","\n","# TODO : ERR -> protocol error..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HRHffWocRTbI"},"source":["!pip install tensorflow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KJlIaLbzSDq6"},"source":["from keras.datasets import mnist\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-V48wXBdSZZN"},"source":["print(\"x_train size : {}\".format(len(x_train)))\n","print(\"y_train size : {}\".format(len(y_train)))\n","\n","print(\"x_test size : {}\".format(len(x_test)))\n","print(\"y_test size : {}\".format(len(y_test)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FnkgulABVN13"},"source":["y_test[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tEqu2gUDUtr4"},"source":["train_data = torch.Tensor(x_train)\n","train_ans = torch.Tensor(y_train)\n","# Label = y_train[num]\n","test_data = torch.Tensor(x_test)\n","test_ans = torch.Tensor(y_test)\n","# Label = y_test[num]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8XTlJR4Vr9O"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import DataLoader, TensorDataset\n","from torchvision import datasets, transforms\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Loes301xVwc6"},"source":["plt.imshow(train_data[0].reshape(28, 28), cmap='gist_yarg')\n","print(y_train[0]) # answer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qN9KFuLHWrJ7"},"source":["train_data_set = TensorDataset(train_data, train_ans)\n","test_data_set = TensorDataset(test_data, test_ans)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uoN2gsFNXw63"},"source":["print(train_data_set[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FXJ8qOBeYHKG"},"source":["train_loader = DataLoader(train_data_set, batch_size = 100, shuffle = True)\n","test_loader = DataLoader(test_data_set, batch_size = 500, shuffle = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ktt-8gn4Yfcq"},"source":["from torchvision.utils import make_grid\n","np.set_printoptions(formatter=dict(int=lambda x : f'{x:4}')) #formatting\n","\n","#first batch\n","for images,labels in train_loader:\n","    break\n","    \n","images.shape\n","# torch.Size([100, 1, 28, 28])\n","# 100개 이미지, 28 x 28 그레이 스케일\n","\n","labels.shape\n","# torch.Size([100])\n","\n","print('Labels:', labels[:12].numpy())\n","im = make_grid(images[:12],nrow=12)\n","plt.figure(figsize=(10,4))\n","plt.imshow(np.transpose(im.numpy(),(2,1,0))) # color, width, height -> whc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zPXdKX6BZvLS"},"source":["# reference\n","\n","# 1. https://github.com/activatedgeek/LeNet-5/blob/master/run.py\n","# 2. https://rueki.tistory.com/99\n","# 3. https://bskyvision.com/418\n","# 4. https://nextjournal.com/gkoehler/pytorch-mnist"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2-o7Qgpcne6Q"},"source":["import numpy as np\n","from datetime import datetime \n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","\n","from torchvision import datasets, transforms\n","\n","import matplotlib.pyplot as plt\n","\n","# check device\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ueFftsqKeZqQ"},"source":["# parameters\n","RANDOM_SEED = 1\n","LEARNING_RATE = 0.001\n","BATCH_SIZE = 100\n","N_EPOCHS = 20\n","IMG_SIZE = 32\n","N_CLASSES = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JkjAPAGJmzw-"},"source":["def train(train_loader, model, criterion, optimizer, device):\n","    '''\n","    Function for the training step of the training loop\n","    '''\n","    model.train()\n","    running_loss = 0\n","    \n","    for X, y_true in train_loader:\n","\n","        optimizer.zero_grad()\n","        \n","        X = X.to(device)\n","        y_true = y_true.to(device)\n","    \n","        # Forward pass\n","        y_hat, _ = model(X) \n","        loss = criterion(y_hat, y_true) \n","        running_loss += loss.item() * X.size(0)\n","\n","        # Backward pass\n","        loss.backward()\n","        optimizer.step()\n","        \n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    return model, optimizer, epoch_loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3sSW_EGrmzzT"},"source":["def validate(valid_loader, model, criterion, device):\n","    '''\n","    Function for the validation step of the training loop\n","    '''\n","    model.eval()\n","    running_loss = 0\n","    \n","    for X, y_true in valid_loader:\n","    \n","        X = X.to(device)\n","        y_true = y_true.to(device)\n","\n","        # Forward pass and record loss\n","        y_hat, _ = model(X) \n","        loss = criterion(y_hat, y_true) \n","        running_loss += loss.item() * X.size(0)\n","\n","    epoch_loss = running_loss / len(valid_loader.dataset)\n","        \n","    return model, epoch_loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VvylZLBmz2Q"},"source":["def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n","    '''\n","    Function defining the entire training loop\n","    '''\n","    \n","    # set objects for storing metrics\n","    best_loss = 1e10\n","    train_losses = []\n","    valid_losses = []\n"," \n","    # Train model\n","    for epoch in range(0, epochs):\n","\n","        # training\n","        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n","        train_losses.append(train_loss)\n","\n","        # validation\n","        with torch.no_grad():\n","            model, valid_loss = validate(valid_loader, model, criterion, device)\n","            valid_losses.append(valid_loss)\n","\n","        if epoch % print_every == (print_every - 1):\n","            \n","            train_acc = get_accuracy(model, train_loader, device=device)\n","            valid_acc = get_accuracy(model, valid_loader, device=device)\n","                \n","            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n","                  f'Epoch: {epoch}\\t'\n","                  f'Train loss: {train_loss:.4f}\\t'\n","                  f'Valid loss: {valid_loss:.4f}\\t'\n","                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n","                  f'Valid accuracy: {100 * valid_acc:.2f}')\n","\n","    plot_losses(train_losses, valid_losses)\n","    \n","    return model, optimizer, (train_losses, valid_losses)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WExNsS_trCLa"},"source":["class LeNet5(nn.Module):\n","\n","    def __init__(self, n_classes):\n","        super(LeNet5, self).__init__()\n","        \n","        self.feature_extractor = nn.Sequential(            \n","            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n","            nn.Tanh(),\n","            nn.AvgPool2d(kernel_size=2),\n","            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n","            nn.Tanh(),\n","            nn.AvgPool2d(kernel_size=2),\n","            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n","            nn.Tanh()\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(in_features=120, out_features=84),\n","            nn.Tanh(),\n","            nn.Linear(in_features=84, out_features=n_classes),\n","        )\n","\n","\n","    def forward(self, x):\n","        x = self.feature_extractor(x)\n","        x = torch.flatten(x, 1)\n","        logits = self.classifier(x)\n","        probs = F.softmax(logits, dim=1)\n","        return logits, probs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sk9_PJ6OrK3w"},"source":["# start\n","\n","torch.manual_seed(RANDOM_SEED)\n","\n","model = LeNet5(N_CLASSES).to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"67ylXzFOrOaY"},"source":["model, optimizer, _ = training_loop(model, criterion, optimizer, train_loader, valid_loader, N_EPOCHS, DEVICE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHGZGuONrZtZ"},"source":[""],"execution_count":null,"outputs":[]}]}