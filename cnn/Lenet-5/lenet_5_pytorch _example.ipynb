{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lenet_5_pytorch _example.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOrcDFMzm/+V+iSIoeFPKwF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"fn0u-N9p--QJ"},"source":["  !cat /etc/issue.net"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LBykuEpt--TH"},"source":["!cat /proc/meminfo"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-K0gOwtQ_Gjl"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qzkOlpq-_JFW"},"source":["!python --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"emld4xGd_SGe"},"source":["!ls -al"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iJDh-2Ar_UxR"},"source":["from google.colab import drive\n","drive.mount('LeNet-5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s-D9oxXK_aZd"},"source":["import numpy as np\n","from datetime import datetime\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","\n","from torchvision import datasets, transforms\n","\n","import matplotlib.pyplot as plt\n","\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XmUIQRh5_00s"},"source":["# Parameters setting\n","\n","RANDOM_SEED = 42\n","LEARNING_RATE = 0.001\n","BATCH_SIZE = 32\n","N_EPOCHS = 15\n","\n","IMG_SIZE = 32\n","N_CLASSES = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LVUDcR4l__9l"},"source":["def get_accuracy(model, data_loader, device):\n","    ''' \n","    전체 data_loader에 대한 예측의 정확도를 계산하는 함수\n","    '''\n","    correct_pred = 0\n","    n = 0\n","\n","    with torch.no_grad():\n","        model.eval()\n","        for X, y_true in data_loader:\n","\n","            X = x.to(device)\n","            y_true = y_true.to(device)\n","\n","            _, y_pob = model(X)\n","            _, predicted_labels = torch.max(y_prob, 1)\n","\n","            n += y_true.size(0)\n","            correct_pred += (predicted_labels == y_true).sum()\n","    return correct_pred.float() / n\n","\n","def plot_losses(train_losses, valid_losses):\n","    '''\n","    trainig 과 validation loss를 시각화 하기 위한 함수\n","    '''\n","\n","    plt.style.use('seaborn')\n","\n","    train_losses = np.array(train_losses)\n","    valid_losses = np.array(valid_losses)\n","\n","    fig, ax = plt.subplots(figsize = (8, 4.5))\n","\n","    ax.plot(train_losses, color = 'green', label = 'Training Loss')\n","    ax.plot(valid_losses, color = 'red', label = 'Validation loss')\n","    ax.set(title = 'Loss over Epochs',\n","           xlabel = 'Epochs',\n","           ylabel = 'Loss')\n","    ax.legend()\n","    fig.show()\n","    plt.style.use('default')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2VrfXOgNAbEv"},"source":["def train(train_loader, model, critorion, optimizer, device):\n","    '''\n","    training loop 의 training 단계에 대한 함수\n","    '''\n","\n","    model.train()\n","    running_loss = 0\n","\n","    for X, y_true in train_loader:\n","\n","        optimizer.zero_grad()\n","\n","        X = X.to(device)\n","        y_true = y_true.to(device)\n","\n","        y_hat, _ = model(X)\n","        loss = critorion(y_hat, y_true)\n","        running_loss += loss.item() * X.size(0)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    return model, optimizer, epoch_loss\n","    \n","\n","def validate(valid_loader, model, criterion, device):\n","    '''\n","    training loop의 validation 단계에 대한 함수\n","    '''\n","   \n","    model.eval()\n","    running_loss = 0\n","    \n","    for X, y_true in valid_loader:\n","    \n","        X = X.to(device)\n","        y_true = y_true.to(device)\n","\n","        # 순전파와 손실 기록하기\n","        y_hat, _ = model(X) \n","        loss = criterion(y_hat, y_true) \n","        running_loss += loss.item() * X.size(0)\n","\n","    epoch_loss = running_loss / len(valid_loader.dataset)\n","        \n","    return model, epoch_loss\n","\n","def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n","    '''\n","    전체 training loop를 정의하는 함수\n","    '''\n","    \n","    # metrics를 저장하기 위한 객체 설정\n","    best_loss = 1e10\n","    train_losses = []\n","    valid_losses = []\n"," \n","    # model 학습하기\n","    for epoch in range(0, epochs):\n","\n","        # training\n","        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n","        train_losses.append(train_loss)\n","\n","        # validation\n","        with torch.no_grad():\n","            model, valid_loss = validate(valid_loader, model, criterion, device)\n","            valid_losses.append(valid_loss)\n","\n","        if epoch % print_every == (print_every - 1):\n","            \n","            train_acc = get_accuracy(model, train_loader, device=device)\n","            valid_acc = get_accuracy(model, valid_loader, device=device)\n","                \n","            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n","                  f'Epoch: {epoch}\\t'\n","                  f'Train loss: {train_loss:.4f}\\t'\n","                  f'Valid loss: {valid_loss:.4f}\\t'\n","                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n","                  f'Valid accuracy: {100 * valid_acc:.2f}')\n","\n","    plot_losses(train_losses, valid_losses)\n","    \n","    return model, optimizer, (train_losses, valid_losses)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7zeAWO8ACJQi"},"source":["# transforms 정의하기\n","transforms = transforms.Compose([transforms.Resize((32, 32)),\n","                                 transforms.ToTensor()])\n","\n","# data set 다운받고 생성하기\n","train_dataset = datasets.MNIST(root='mnist_data', \n","                               train=True, \n","                               transform=transforms,\n","                               download=True)\n","\n","valid_dataset = datasets.MNIST(root='mnist_data', \n","                               train=False, \n","                               transform=transforms)\n","\n","# data loader 정의하기\n","train_loader = DataLoader(dataset=train_dataset, \n","                          batch_size=BATCH_SIZE, \n","                          shuffle=True)\n","\n","valid_loader = DataLoader(dataset=valid_dataset, \n","                          batch_size=BATCH_SIZE, \n","                          shuffle=False)\n","\n","# 불러온 MNIS data 확인하기\n","ROW_IMG = 10\n","N_ROWS = 5\n","\n","fig = plt.figure()\n","for index in range(1, ROW_IMG * N_ROWS + 1):\n","    plt.subplot(N_ROWS, ROW_IMG, index)\n","    plt.axis('off')\n","    plt.imshow(train_dataset.data[index], cmap='gray_r')\n","fig.suptitle('MNIST Dataset - preview');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F1bSTCI1CNP2"},"source":["class LeNet5(nn.Module):\n","\n","    def __init__(self, n_classes):\n","        super(LeNet5, self).__init__()\n","        \n","        self.feature_extractor = nn.Sequential(            \n","            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n","            nn.Tanh(),\n","            nn.AvgPool2d(kernel_size=2),\n","            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n","            nn.Tanh(),\n","            nn.AvgPool2d(kernel_size=2),\n","            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n","            nn.Tanh()\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(in_features=120, out_features=84),\n","            nn.Tanh(),\n","            nn.Linear(in_features=84, out_features=n_classes),\n","        )\n","\n","\n","    def forward(self, x):\n","        x = self.feature_extractor(x)\n","        x = torch.flatten(x, 1)\n","        logits = self.classifier(x)\n","        probs = F.softmax(logits, dim=1)\n","        return logits, probs\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Pj2tqApCvR3"},"source":["torch.manual_seed(RANDOM_SEED)\n","\n","model = LeNet5(N_CLASSES).to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","criterion = nn.CrossEntropyLoss()\n","\n","\n","\n","model, optimizer, _ = training_loop(model, criterion, optimizer, train_loader, \n","                                    valid_loader, N_EPOCHS, DEVICE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m_Y1vu42C3i_"},"source":[""],"execution_count":null,"outputs":[]}]}